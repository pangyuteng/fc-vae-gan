{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data explorer\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# configure Tensorflow\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf.gpu_options.allow_growth=True\n",
    "\n",
    "# intialize TF\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# iterate through data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff.\n",
    "from fcvaegan import (\n",
    "    Model,\n",
    "    MODEL_DIR,\n",
    "    INPUT_TENSOR_NAME,\n",
    "    SIGNATURE_NAME,\n",
    "    read_and_decode,\n",
    "    PARAMS,\n",
    "    W,H,C,CY,\n",
    "    TRAIN_DIR,\n",
    "    NUM_EXAMPLES_TRAIN,\n",
    "    NUM_EXAMPLES_VALIDATION,\n",
    "    NUM_EXAMPLES_TEST,\n",
    ")\n",
    "params = dict(PARAMS)\n",
    "params.update({\n",
    "    'is_training':True, # this impact inferences....due to batch norm...?\n",
    "    'batch_size':4, # <<--- 4 is good for 6gb gpu.\n",
    "})\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "def _input_fn(training_dir, training_filename, batch_size=batch_size):\n",
    "    test_file = os.path.join(training_dir, training_filename)\n",
    "    filename_queue = tf.train.string_input_producer([test_file])\n",
    "\n",
    "    image, label = read_and_decode(filename_queue)\n",
    "    images, labels = tf.train.batch(\n",
    "        [image, label], batch_size=batch_size,\n",
    "        capacity=1000 + 10 * batch_size)\n",
    "    return {INPUT_TENSOR_NAME: images}, labels\n",
    "\n",
    "\n",
    "#def eval_input_fn(training_dir=TRAIN_DIR, batch_size=batch_size, params=None):\n",
    "#    return _input_fn(training_dir, 'validation.tfrecords', batch_size=batch_size)\n",
    "#tf_images,tf_labels = eval_input_fn(batch_size=batch_size)\n",
    "\n",
    "def train_input_fn(training_dir=TRAIN_DIR, batch_size=batch_size, params=None):\n",
    "    return _input_fn(training_dir, 'train.tfrecords', batch_size=batch_size)\n",
    "tf_images,tf_labels = train_input_fn(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord,sess=sess)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('/media/external/scisoft/fc-vae-gan/data/label.yml','r') as f:\n",
    "    label_dict = yaml.load(f.read())\n",
    "max_labe_num = len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count,bins = np.histogram([],bins=max_labe_num,range=(0,max_labe_num))\n",
    "total_count = np.array(total_count)\n",
    "for n in range(NUM_EXAMPLES_TRAIN):\n",
    "    img, lbl = sess.run([tf_images,tf_labels])\n",
    "    count,bins = np.histogram(list((lbl.ravel())),bins=max_labe_num,range=(0,max_labe_num))\n",
    "    total_count += np.array(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeroplane\n",
      "bed\n",
      "bedclothes\n",
      "bicycle\n",
      "bird\n",
      "boat\n",
      "bottle\n",
      "building\n",
      "bus\n",
      "cabinet\n",
      "car\n",
      "cat\n",
      "ceiling\n",
      "chair\n",
      "cloth\n",
      "cow\n",
      "curtain\n",
      "dog\n",
      "door\n",
      "fence\n",
      "floor\n",
      "grass\n",
      "ground\n",
      "horse\n",
      "motorbike\n",
      "mountain\n",
      "person\n",
      "picture\n",
      "pottedplant\n",
      "road\n",
      "rock\n",
      "rug\n",
      "sheep\n",
      "shelves\n",
      "sky\n",
      "snow\n",
      "sofa\n",
      "table\n",
      "track\n",
      "train\n",
      "tree\n",
      "tvmonitor\n",
      "unknown\n",
      "wall\n",
      "water\n",
      "window\n"
     ]
    }
   ],
   "source": [
    "for ind in np.argwhere(total_count>np.percentile(total_count,90)):\n",
    "    print(label_dict[ind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP = False\n",
    "if STOP:\n",
    "    coord.request_stop()\n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
